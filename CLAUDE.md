# Ebbinghaus Memory-Enhanced LLM - æ ¸å¿ƒè®¾è®¡æ–‡æ¡£

## ğŸ¯ æ ¸å¿ƒæ€è·¯

é€šè¿‡è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ä¸ºæ¯ä¸ªtokenåœ¨æ¯ä¸€å±‚å»ºç«‹ç‹¬ç«‹çš„è®°å¿†æ¨¡å‹ï¼Œå®ç°çœŸæ­£çš„åŠ¨æ€KV cacheç®¡ç†ã€‚

**è®¾è®¡ç†å¿µ**: æ¨¡æ‹Ÿäººç±»è®°å¿†çš„è‡ªç„¶è¡°å‡è¿‡ç¨‹ï¼Œå½“tokenæ²¡æœ‰è¢«å…³æ³¨æ—¶ï¼Œå¯ä»¥ä»ç›¸åº”å±‚çš„cacheä¸­åˆ é™¤ï¼Œä¸åŒå±‚å¯ä»¥æœ‰ä¸åŒçš„cacheé•¿åº¦ã€‚

## ğŸ”¬ è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿åŸç†

ç³»ç»ŸåŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿å…¬å¼ï¼š
```
R = e^(-t/S)
```
å…¶ä¸­ï¼š
- **R**: è®°å¿†ä¿æŒç‡ï¼ˆæƒé‡ï¼‰[0, 1]
- **t**: æ—¶é—´æ­¥æ•°ï¼ˆæ¯tokenå¢åŠ 0.05ï¼‰
- **S**: è®°å¿†å¼ºåº¦ï¼ˆåˆå§‹5.0ï¼Œéšattentionå¢å¼ºï¼‰

### å…³é”®å®ç°åŸåˆ™
**æ¯ç”Ÿæˆä¸€ä¸ªtokenéƒ½å¿…é¡»æ›´æ–°è®°å¿†å‚æ•°**ã€‚è¿™æ˜¯æ ¸å¿ƒè¦æ±‚ - è‰¾å®¾æµ©æ–¯æ¨¡å‹çš„ç§‘å­¦å‡†ç¡®æ€§ä¾èµ–äºæŒç»­çš„æ—¶é—´æ¨è¿›å’ŒåŸºäºattentionçš„è®°å¿†æ›´æ–°ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### ä¸¤ç§ç”Ÿæˆæ¨¡å¼

1. **Baselineæ¨¡å¼** (`generate_baseline`)
   - æ ‡å‡†transformerç”Ÿæˆï¼Œä½¿ç”¨forward()
   - ä¸åº”ç”¨ä»»ä½•è®°å¿†æœºåˆ¶
   - ä½œä¸ºæ€§èƒ½åŸºå‡†

2. **Memory Enhancedæ¨¡å¼** (`generate_memory_enhanced`)
   - ä½¿ç”¨è‡ªç„¶è®°å¿†æƒé‡ï¼ˆ0-1èŒƒå›´ï¼‰ï¼Œæ— äººä¸ºé™åˆ¶
   - å½“æƒé‡ä½äºé˜ˆå€¼æ—¶æ‰§è¡Œç¡¬åˆ é™¤ï¼ˆé»˜è®¤0.01ï¼‰
   - æ”¯æŒæ¯å±‚ä¸åŒé•¿åº¦çš„cache
   - åˆ é™¤tokenååœæ­¢æ›´æ–°å…¶è®°å¿†
   - æ— äººä¸ºæœ€å°æƒé‡çº¦æŸ

### å…³é”®è®¾è®¡å†³ç­–

1. **åŸºäºForwardçš„ç”Ÿæˆ**: ç›´æ¥ä½¿ç”¨`model.forward()`è€Œä¸æ˜¯`transformers.generate()`ï¼Œä»¥å®ç°æ¯tokençš„è®°å¿†æ›´æ–°
2. **æ¯tokenæ›´æ–°**: æ¯ç”Ÿæˆä¸€ä¸ªtokenåéƒ½å¿…é¡»æ›´æ–°è®°å¿†
3. **å±‚é—´ç‹¬ç«‹**: æ¯å±‚ç‹¬ç«‹å†³å®šæ˜¯å¦åˆ é™¤tokenï¼Œæ”¯æŒä¸åŒå±‚çš„ä¸åŒcacheé•¿åº¦
4. **çœŸæ­£çš„ç¡¬åˆ é™¤**: ä½¿ç”¨VariableLengthCacheå®ç°çœŸæ­£çš„tokenåˆ é™¤ï¼Œè€Œä¸æ˜¯è½¯å±è”½

## ğŸ“Š æ€§èƒ½ç‰¹å¾

- **Baseline**: ~18 tokens/sï¼ˆæ ‡å‡†ç”Ÿæˆï¼‰
- **Memory Enhanced**: ~5-6 tokens/sï¼ˆåŠ¨æ€cacheç®¡ç†ï¼‰

Memory Enhancedæ¨¡å¼è™½ç„¶é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ—¶èƒ½å¤Ÿï¼š
- è‡ªåŠ¨åˆ é™¤ä½æƒé‡tokenï¼Œé‡Šæ”¾å†…å­˜
- æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£
- Cacheåˆ é™¤ç‡é€šå¸¸åœ¨20-40%

## ğŸ”§ æ ¸å¿ƒå®ç°

### è®°å¿†ç®¡ç†å™¨ (`memollm/memory.py`)

```python
class LayerTokenMemory:
    S: float = 5.0  # è®°å¿†å¼ºåº¦
    t: int = 0      # æ—¶é—´æ­¥æ•°
    
    def get_retention_weight(self) -> float:
        return math.exp(-self.t / self.S)
    
    def update_memory(self, attention_weight: float):
        self.S += attention_weight  # å¢å¼ºè®°å¿†
        if attention_weight >= 0.01:
            self.t = 0  # é‡è¦tokené‡ç½®æ—¶é—´
    
    def step_time(self):
        self.t += 0.05  # æ¯tokenæ—¶é—´æ¨è¿›
```

### å˜é•¿Cacheå®ç° (`memollm/model.py`)

```python
class VariableLengthCache:
    def delete_tokens(self, layer_idx: int, positions_to_delete: List[int]):
        """åˆ é™¤æŒ‡å®šå±‚çš„ç‰¹å®štokenä½ç½®"""
        # ä¸ºæŒ‡å®šå±‚åˆ›å»ºä¿ç•™mask
        keep_mask = torch.ones(seq_len, dtype=torch.bool)
        for pos in positions_to_delete:
            keep_mask[pos] = False
        
        # åº”ç”¨maskåˆ°è¯¥å±‚cache
        self.key_cache[layer_idx] = key_cache[:, :, keep_mask, :]
        self.value_cache[layer_idx] = value_cache[:, :, keep_mask, :]
```

### Memory Enhancedç”Ÿæˆæµç¨‹:
1. è·å–å½“å‰åºåˆ—é•¿åº¦
2. æ£€ç´¢è®°å¿†æƒé‡ï¼ˆå¸¦ç¼“å­˜ï¼‰
3. å¯¹æ¯å±‚åº”ç”¨è®°å¿†æƒé‡
4. è¯†åˆ«éœ€è¦åˆ é™¤çš„tokenï¼ˆä½äºé˜ˆå€¼ï¼‰
5. **æ¯å±‚ç‹¬ç«‹åˆ é™¤token**ä»KV cache
6. Forwardä¼ æ’­ï¼ˆä½¿ç”¨ä¿®æ”¹åçš„cacheï¼‰
7. æ›´æ–°æ‰€æœ‰å±‚è®°å¿†ï¼ˆè·³è¿‡å·²åˆ é™¤tokenï¼‰
8. é‡‡æ ·ä¸‹ä¸€ä¸ªtoken
9. æ‰€æœ‰è®°å¿†æ—¶é—´æ­¥è¿›
10. **æ¸…é™¤ç¼“å­˜** â† å…³é”®ï¼
11. é‡å¤

## ğŸ¯ åŸºæœ¬ä½¿ç”¨

```python
from memollm import EbbinghausLLM

llm = EbbinghausLLM("Qwen/Qwen2.5-0.5B-Instruct")

# æ ‡å‡†ç”Ÿæˆï¼ˆåŸºå‡†ï¼‰
result = llm.generate(
    "è§£é‡Šäººå·¥æ™ºèƒ½",
    max_new_tokens=100,
    generation_mode="baseline"
)

# è®°å¿†å¢å¼ºç”Ÿæˆï¼ˆæ”¯æŒæ¯å±‚ä¸åŒé•¿åº¦cacheï¼‰
result = llm.generate(
    "å†™ä¸€ä¸ªè¯¦ç»†åˆ†æ",
    max_new_tokens=500,
    generation_mode="memory_enhanced",
    hard_delete_threshold=0.01  # ç¡¬åˆ é™¤é˜ˆå€¼
)

print(f"Cacheåˆ é™¤ç‡: {result['cache_deletion_percentage']:.2f}%")
print(f"æ¯å±‚cacheé•¿åº¦: {result['layer_cache_lengths'][:5]}")
```

## ğŸ“ æ ¸å¿ƒé…ç½®

### è®°å¿†ç³»ç»Ÿå‚æ•°:
- åˆå§‹è®°å¿†å¼ºåº¦(S): 5.0
- æ¯tokenæ—¶é—´å¢é‡: 0.05
- Attentioné‡ç½®é˜ˆå€¼: 0.01
- ç¡¬åˆ é™¤é˜ˆå€¼: 0.01ï¼ˆå¯é…ç½®ï¼‰

### å…³é”®ç‰¹æ€§:
- è®°å¿†æƒé‡è‡ªç„¶èŒƒå›´: [0, 1]
- æ— äººä¸ºé™åˆ¶æˆ–æœ€å°é˜ˆå€¼
- æ¯å±‚ç‹¬ç«‹åˆ é™¤å†³ç­–
- æ”¯æŒä¸åŒå±‚çš„ä¸åŒcacheé•¿åº¦

---

**æ ¸å¿ƒæ€æƒ³**: é€šè¿‡è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ä¸ºæ¯ä¸ªtokenåœ¨æ¯ä¸€å±‚å»ºç«‹ç‹¬ç«‹è®°å¿†æ¨¡å‹ï¼Œå½“tokenæ²¡æœ‰è¢«å…³æ³¨æ—¶å¯ä»¥éšæ—¶åˆ é™¤ï¼Œå®ç°çœŸæ­£çš„åŠ¨æ€KV cacheç®¡ç†ã€‚

**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**ç‰ˆæœ¬**: 3.0 (Variable-Length Cache)